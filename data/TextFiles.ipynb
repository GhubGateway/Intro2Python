{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iSwiin/Intro2Python/blob/main/data/TextFiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3COyF_uFfb"
      },
      "source": [
        "# Text Files"
      ],
      "id": "Ay3COyF_uFfb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t-gQ2f6uFfd"
      },
      "source": [
        "Within Python, there are pre-built functions that can <ins>read</ins>, <ins>update</ins>, <ins>delete</ins>, and <ins>create files</ins>. In Python, there are two types of files that can be manipulated: <ins>**binary files**</ins> and <ins>**text files**</ins>. We will deal with the latter. **Text files** include *text* files (.txt), comma-separated values (.csv), etc. We will go over one method, but it's good to keep in mind there are many other ways to do this."
      ],
      "id": "7t-gQ2f6uFfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EZni4DbuFfd"
      },
      "source": [
        "<img src=\"https://hkperugu.com/uploads/Class3_image1.jfif\" width=\"400\">"
      ],
      "id": "5EZni4DbuFfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2sDx0W6uFfd"
      },
      "source": [
        "By the end of this section, you will learn:\n",
        "* [**to maniuplate text files**](#How-to-open-a-text-file)\n",
        "* [**about cleaning text files**](#Cleaning-up-a-file-line-by-line)\n",
        "* [**to make text file data useable**](#Storing-column-data-in-an-array)"
      ],
      "id": "x2sDx0W6uFfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8VLJb_IuFfe"
      },
      "source": [
        "## How to open a text file"
      ],
      "id": "c8VLJb_IuFfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOsGOk9quFfe"
      },
      "source": [
        "To **open a file**, we can use the built-in Python function **```open()```**. Our input arguments will be:\n",
        "```python\n",
        "open('text file name','mode')\n",
        "```\n",
        "\n",
        "There are **four modes** we can use to open a text file:\n",
        "\n",
        "|Mode|Description|\n",
        "|-|-:|\n",
        "|'r'|to read file, default|\n",
        "|'a'|to add to a file|\n",
        "|'w'|to overwrite a file|\n",
        "|'x'|to create a file|\n",
        "\n",
        "Here is an example of opening a text file to read:"
      ],
      "id": "KOsGOk9quFfe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1idhdsfuFfe"
      },
      "outputs": [],
      "source": [
        "# Create variable that will store file\n",
        "ofile =open('d18o_datafile.csv','r')\n",
        "# if the file is in a different, you will need to use the file path"
      ],
      "id": "n1idhdsfuFfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8vnxbsbuFfe"
      },
      "source": [
        "To <ins>**view the contents of the file**</ins>, we can use the **```read()```** function:"
      ],
      "id": "x8vnxbsbuFfe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxq6TAskuFff",
        "outputId": "85d361d8-12df-4575-e99d-6270ffdb0aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DAY,    1 \n",
            "  1, -14.05\n",
            "  2, -14.05\n",
            "  3, -14.05\n",
            "  4, -14.05\n",
            "  5, -14.05\n",
            "  6, -14.05\n",
            "  7, -14.05\n",
            "  8, -14.05\n",
            "  9, -14.05\n",
            " 10, -14.05\n",
            " 11, -14.05\n",
            " 12, -14.05\n",
            " 13, -14.05\n",
            " 14, -14.05\n",
            " 15, -14.05\n",
            " 16, -14.05\n",
            " 17, -14.05\n",
            " 18, -14.05\n",
            " 19, -14.05\n",
            " 20, -14.05\n",
            " 21, -14.05\n",
            " 22, -14.05\n",
            " 23, -14.05\n",
            " 24, -14.05\n",
            " 25, -14.05\n",
            " 26, -14.05\n",
            " 27, -14.05\n",
            " 28, -14.05\n",
            " 29, -14.05\n",
            " 30, -14.05\n",
            " 31, -14.05\n",
            " 32, -14.05\n",
            " 33, -14.05\n",
            " 34, -14.05\n",
            " 35, -14.05\n",
            " 36, -14.05\n",
            " 37, -14.05\n",
            " 38, -14.05\n",
            " 39, -14.05\n",
            " 40, -14.05\n",
            " 41, -14.05\n",
            " 42, -14.05\n",
            " 43, -14.05\n",
            " 44, -14.05\n",
            " 45, -14.05\n",
            " 46, -14.05\n",
            " 47, -14.05\n",
            " 48, -14.05\n",
            " 49, -14.05\n",
            " 50, -14.05\n",
            " 51, -14.05\n",
            " 52, -14.05\n",
            " 53, -14.05\n",
            " 54, -14.05\n",
            " 55, -14.05\n",
            " 56, -14.05\n",
            " 57, -14.05\n",
            " 58, -14.05\n",
            " 59, -14.05\n",
            " 60, -14.05\n",
            " 61, -14.05\n",
            " 62, -14.05\n",
            " 63, -14.05\n",
            " 64, -14.05\n",
            " 65, -14.05\n",
            " 66, -14.05\n",
            " 67, -14.05\n",
            " 68, -14.05\n",
            " 69, -14.05\n",
            " 70, -14.05\n",
            " 71, -14.05\n",
            " 72, -14.05\n",
            " 73, -14.05\n",
            " 74, -14.05\n",
            " 75, -14.05\n",
            " 76, -14.05\n",
            " 77, -14.05\n",
            " 78, -14.05\n",
            " 79, -14.05\n",
            " 80, -14.05\n",
            " 81, -14.05\n",
            " 82, -14.05\n",
            " 83, -14.05\n",
            " 84, -14.05\n",
            " 85, -14.05\n",
            " 86, -14.05\n",
            " 87, -14.05\n",
            " 88, -14.05\n",
            " 89, -14.05\n",
            " 90, -14.05\n",
            " 91, -14.05\n",
            " 92, -14.05\n",
            " 93, -14.05\n",
            " 94, -14.05\n",
            " 95, -14.05\n",
            " 96, -14.05\n",
            " 97, -14.05\n",
            " 98, -14.05\n",
            " 99, -14.05\n",
            "100, -14.05\n",
            "101, -14.05\n",
            "102, -14.05\n",
            "103, -14.05\n",
            "104, -14.05\n",
            "105, -14.05\n",
            "106, -14.05\n",
            "107, -14.05\n",
            "108, -14.05\n",
            "109, -14.05\n",
            "110, -14.05\n",
            "111, -14.05\n",
            "112, -14.05\n",
            "113, -14.05\n",
            "114, -14.05\n",
            "115, -14.05\n",
            "116, -14.05\n",
            "117, -14.05\n",
            "118, -14.05\n",
            "119, -14.05\n",
            "120, -14.05\n",
            "121, -14.05\n",
            "122, -14.05\n",
            "123, -14.05\n",
            "124, -14.05\n",
            "125, -14.05\n",
            "126, -14.05\n",
            "127, -14.05\n",
            "128, -14.05\n",
            "129, -14.05\n",
            "130, -14.05\n",
            "131, -14.05\n",
            "132, -14.05\n",
            "133, -14.05\n",
            "134, -14.05\n",
            "135, -14.05\n",
            "136, -14.05\n",
            "137, -14.05\n",
            "138, -14.05\n",
            "139, -14.05\n",
            "140, -14.05\n",
            "141, -14.05\n",
            "142, -14.05\n",
            "143, -14.05\n",
            "144, -14.05\n",
            "145, -14.05\n",
            "146, -14.05\n",
            "147, -14.05\n",
            "148, -14.05\n",
            "149, -14.05\n",
            "150, -14.05\n",
            "151, -14.05\n",
            "152, -14.05\n",
            "153, -14.05\n",
            "154, -14.05\n",
            "155, -14.05\n",
            "156, -14.05\n",
            "157, -14.05\n",
            "158, -14.05\n",
            "159, -14.05\n",
            "160, -14.05\n",
            "161, -14.05\n",
            "162, -14.05\n",
            "163, -14.05\n",
            "164, -14.05\n",
            "165, -14.05\n",
            "166, -14.05\n",
            "167, -14.05\n",
            "168, -14.05\n",
            "169, -14.05\n",
            "170, -14.05\n",
            "171, -14.05\n",
            "172, -14.05\n",
            "173, -14.05\n",
            "174, -14.05\n",
            "175, -14.05\n",
            "176, -14.05\n",
            "177, -14.05\n",
            "178, -14.05\n",
            "179, -14.05\n",
            "180, -14.05\n",
            "181, -14.05\n",
            "182, -14.05\n",
            "183, -14.05\n",
            "184, -14.05\n",
            "185, -14.05\n",
            "186, -14.05\n",
            "187, -14.05\n",
            "188, -14.05\n",
            "189, -14.05\n",
            "190, -14.05\n",
            "191, -14.05\n",
            "192, -14.05\n",
            "193, -14.05\n",
            "194, -14.05\n",
            "195, -14.05\n",
            "196, -14.05\n",
            "197, -14.05\n",
            "198, -14.05\n",
            "199, -14.05\n",
            "200, -14.05\n",
            "201, -14.05\n",
            "202, -14.05\n",
            "203, -14.05\n",
            "204, -14.05\n",
            "205, -14.05\n",
            "206, -14.05\n",
            "207, -14.05\n",
            "208, -14.16\n",
            "209, -14.47\n",
            "210, -14.76\n",
            "211, -14.78\n",
            "212, -14.71\n",
            "213, -14.79\n",
            "214, -14.78\n",
            "215, -14.49\n",
            "216, -14.53\n",
            "217, -14.26\n",
            "218, -13.84\n",
            "219, -13.92\n",
            "220, -13.90\n",
            "221, -13.81\n",
            "222, -13.71\n",
            "223, -13.74\n",
            "224, -13.78\n",
            "225, -13.78\n",
            "226, -13.80\n",
            "227, -13.77\n",
            "228, -13.83\n",
            "229, -13.91\n",
            "230, -13.98\n",
            "231, -14.01\n",
            "232, -13.97\n",
            "233, -13.95\n",
            "234, -13.90\n",
            "235, -13.91\n",
            "236, -13.92\n",
            "237, -13.92\n",
            "238, -13.85\n",
            "239, -13.77\n",
            "240, -13.72\n",
            "241, -13.77\n",
            "242, -13.75\n",
            "243, -13.77\n",
            "244, -13.77\n",
            "245, -13.78\n",
            "246, -14.02\n",
            "247, -14.23\n",
            "248, -14.15\n",
            "249, -14.10\n",
            "250, -14.07\n",
            "251, -14.05\n",
            "252, -14.03\n",
            "253, -14.02\n",
            "254, -14.01\n",
            "255, -14.00\n",
            "256, -13.99\n",
            "257, -13.98\n",
            "258, -13.97\n",
            "259, -13.96\n",
            "260, -13.96\n",
            "261, -13.95\n",
            "262, -13.95\n",
            "263, -13.94\n",
            "264, -13.94\n",
            "265, -13.93\n",
            "266, -13.93\n",
            "267, -13.93\n",
            "268, -13.92\n",
            "269, -13.92\n",
            "270, -13.92\n",
            "271, -13.92\n",
            "272, -13.91\n",
            "273, -13.91\n",
            "274, -13.91\n",
            "275, -13.91\n",
            "276, -13.90\n",
            "277, -13.90\n",
            "278, -13.90\n",
            "279, -13.90\n",
            "280, -13.90\n",
            "281, -13.89\n",
            "282, -13.89\n",
            "283, -13.89\n",
            "284, -13.89\n",
            "285, -13.89\n",
            "286, -13.89\n",
            "287, -13.89\n",
            "288, -13.88\n",
            "289, -13.88\n",
            "290, -13.88\n",
            "291, -13.88\n",
            "292, -13.88\n",
            "293, -13.88\n",
            "294, -13.88\n",
            "295, -13.88\n",
            "296, -13.87\n",
            "297, -13.87\n",
            "298, -13.87\n",
            "299, -13.87\n",
            "300, -13.87\n",
            "301, -13.87\n",
            "302, -13.87\n",
            "303, -13.87\n",
            "304, -13.87\n",
            "305, -13.87\n",
            "306, -13.87\n",
            "307, -13.87\n",
            "308, -13.86\n",
            "309, -13.86\n",
            "310, -13.86\n",
            "311, -13.86\n",
            "312, -13.86\n",
            "313, -13.86\n",
            "314, -13.86\n",
            "315, -13.86\n",
            "316, -13.86\n",
            "317, -13.86\n",
            "318, -13.86\n",
            "319, -13.86\n",
            "320, -13.86\n",
            "321, -13.86\n",
            "322, -13.86\n",
            "323, -13.86\n",
            "324, -13.85\n",
            "325, -13.85\n",
            "326, -13.85\n",
            "327, -13.85\n",
            "328, -13.85\n",
            "329, -13.85\n",
            "330, -13.85\n",
            "331, -13.85\n",
            "332, -13.85\n",
            "333, -13.85\n",
            "334, -13.85\n",
            "335, -13.85\n",
            "336, -13.85\n",
            "337, -13.85\n",
            "338, -13.85\n",
            "339, -13.85\n",
            "340, -13.85\n",
            "341, -13.85\n",
            "342, -13.85\n",
            "343, -13.85\n",
            "344, -13.85\n",
            "345, -13.85\n",
            "346, -13.85\n",
            "347, -13.85\n",
            "348, -13.84\n",
            "349, -13.84\n",
            "350, -13.84\n",
            "351, -13.84\n",
            "352, -13.84\n",
            "353, -13.84\n",
            "354, -13.84\n",
            "355, -13.84\n",
            "356, -13.84\n",
            "357, -13.84\n",
            "358, -13.84\n",
            "359, -13.84\n",
            "360, -13.84\n",
            "361, -13.84\n",
            "362, -13.84\n",
            "363, -13.84\n",
            "364, -13.84\n",
            "365, -13.84\n",
            "366, -13.84\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create variable that will store file\n",
        "ofile =open('d18o_datafile.csv','r')\n",
        "print(ofile.read())"
      ],
      "id": "rxq6TAskuFff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AfqT2TpuFff"
      },
      "source": [
        "Notice that we have commas separating each value within our list. We'll need to go line-by-line to clean it up."
      ],
      "id": "3AfqT2TpuFff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWqabssWuFff"
      },
      "source": [
        "## Cleaning up a file line-by-line"
      ],
      "id": "QWqabssWuFff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3VnUOXGuFff"
      },
      "source": [
        "To clean up a file, we can use a **```for```** loop. We will also use the **```strip()```** and **```split()```** functions. The **```strip()```** function will <ins>**remove any unnecessary whitespaces**</ins> and the **```split()```** function will <ins>**split a string into a list**</ins>."
      ],
      "id": "f3VnUOXGuFff"
    },
    {
      "cell_type": "code",
      "source": [
        "# example of the strip() and split() functions\n",
        "\n",
        "variable = \"     pink    \"\n",
        "x = variable.strip()\n",
        "print(\"my favourite colour is \" + x)\n",
        "\n",
        "variable1 = \"blue, red, yellow\"\n",
        "y = variable1.split()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j8QxBeEzJ7E",
        "outputId": "3085312a-1d91-48be-8a8c-0337854d1e8b"
      },
      "id": "5j8QxBeEzJ7E",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my favourite colour is pink\n",
            "['blue,', 'red,', 'yellow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jef6aJSzuFff"
      },
      "outputs": [],
      "source": [
        "# First we open the file to read it\n",
        "ofile =open('d18o_datafile.csv','r')\n",
        "\n",
        "# Use a for loop to go through the file line-by-line\n",
        "for line in ofile:\n",
        "    cline = line.strip().split(',')"
      ],
      "id": "jef6aJSzuFff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpcZWYbguFfg"
      },
      "source": [
        "Since we have titles for each column in our text file, we'll have to create <ins>*another conditional statement*</ins> within our **```for```** loop. We can use the logical operator **```not```** to tell our code to also clean our line with the titles (in this case, ```DAY``` and ```1```)."
      ],
      "id": "XpcZWYbguFfg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0e-VE6luFfg"
      },
      "outputs": [],
      "source": [
        "# First we open the file to read it\n",
        "ofile =open('d18o_datafile.csv','r')\n",
        "\n",
        "# Use a for loop to go through the file line-by-line\n",
        "for line in ofile:\n",
        "\n",
        "    # Skip the line that has our titles\n",
        "    if not line.startswith('DAY'):\n",
        "\n",
        "        # Remove the newline characters and split the line at the commas\n",
        "        cline = line.strip().split(',')"
      ],
      "id": "q0e-VE6luFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nC2S5kTuFfg"
      },
      "source": [
        "Even though we cleaned up our lines, our data within the file is still not useable. We'll need to store each column in an <ins>**_array_**</ins>."
      ],
      "id": "9nC2S5kTuFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqpNBJLjuFfg"
      },
      "source": [
        "## Storing column data in an array"
      ],
      "id": "XqpNBJLjuFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdn0wJgfuFfg"
      },
      "source": [
        "Now that we've cleaned up the file, we are going to <ins>**store our column data in an array**</ins> using the **```append()```** function. We will also need to store our column data as *floats* by using the **```float()```** function."
      ],
      "id": "kdn0wJgfuFfg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OVQFBe7uFfg"
      },
      "outputs": [],
      "source": [
        "import numpy as np #import the library to create arrays\n",
        "\n",
        "# First we open the file to read it\n",
        "ofile =open('d18o_datafile.csv','r')\n",
        "\n",
        "# Create two empty lists to populate with column data\n",
        "days = []\n",
        "d18o = []\n",
        "\n",
        "# Use a for loop to go through the file line-by-line\n",
        "for line in ofile:\n",
        "\n",
        "    # Skip the line that has our titles\n",
        "    if not line.startswith('DAY'):\n",
        "\n",
        "        # now remove the newline characters and split the line at the commas\n",
        "        cline = line.strip().split(',')\n",
        "\n",
        "        # append column data to the empty lists, as floats\n",
        "        days.append(float(cline[0])) # column 1\n",
        "        d18o.append(float(cline[1])) # column 2\n",
        "\n",
        "# Convert data from lists to arrays\n",
        "days = np.array(days)\n",
        "d18o = np.array(d18o)"
      ],
      "id": "9OVQFBe7uFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yNnC88zuFfg"
      },
      "source": [
        "**_Now_** we can plot our data, apply mathematical functions, etc.!"
      ],
      "id": "6yNnC88zuFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfesJTeTuFfg"
      },
      "source": [
        "## Summary"
      ],
      "id": "rfesJTeTuFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cOD2168uFfg"
      },
      "source": [
        "* We can use the [**```open()```** function to open files and **```read()```** function to view a file's contents](#How-to-open-a-text-file)\n",
        "\n",
        "\n",
        "* To make data within a file useable, we can follow these steps:\n",
        "    1. Use a **```for```** loop to [**clean the file**](#Cleaning-up-a-file-line-by-line)\n",
        "    2. Add **another conditional** with the **```not```** statement to also [**clean the titles**](#Cleaning-up-a-file-line-by-line) of the columns\n",
        "    3. Use the **```append()```** function and **```float()```** to [store the data in an array](#Storing-column-data-in-an-array)"
      ],
      "id": "-cOD2168uFfg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgAIZUdDuFfh"
      },
      "source": [
        "## Exercise"
      ],
      "id": "UgAIZUdDuFfh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHMNjZc3uFfh"
      },
      "source": [
        "1. Use the function **```readline()```** to **read the tenth line** from the file **```npark_state.csv```**."
      ],
      "id": "EHMNjZc3uFfh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdJMLcYwuFfh"
      },
      "outputs": [],
      "source": [
        "# answer\n",
        "\n",
        "file_path = 'npark_state.csv'\n",
        "\n",
        "# Open the file in read mode\n",
        "with open(file_path, 'r') as file:\n",
        "    # Skip the first nine lines\n",
        "    for i in range(9):\n",
        "        file.readline()\n",
        "\n",
        "    # Read the tenth line\n",
        "    tenth_line = file.readline()\n",
        "    print(tenth_line)\n",
        "\n"
      ],
      "id": "tdJMLcYwuFfh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U91D82C_uFfh"
      },
      "source": [
        "2. **Add the following line** to the file **```npark_state.csv```**: <ins>\"There are 63 National Parks within the U.S.\"</ins> View the file after adding to it."
      ],
      "id": "U91D82C_uFfh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZuGNNsXuFfh"
      },
      "outputs": [],
      "source": [
        "# answer\n",
        "\n",
        "file_path = 'npark_state.csv'\n",
        "line_to_add = \"There are 63 National Parks within the U.S.\\n\"  # Adding a newline character at the end\n",
        "\n",
        "# Open the file in append mode and write the new line\n",
        "with open(file_path, 'a') as file:\n",
        "    file.write(line_to_add)\n",
        "\n",
        "# View the file after adding the line\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n"
      ],
      "id": "7ZuGNNsXuFfh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQF5kDkfuFfh"
      },
      "source": [
        "3. **Create a pie chart** using the text file: **```degcon_21.txt```**. This file contains the percentage of bachelor's degrees conferred at the University at Buffalo between July 1, 2021 and June 30, 2022."
      ],
      "id": "JQF5kDkfuFfh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijeWGu8MuFfh"
      },
      "outputs": [],
      "source": [
        "# insert code here\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = 'degcon_21.txt'\n",
        "\n",
        "# Read the data from the file\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Processing data into labels and percentages\n",
        "labels = []\n",
        "percentages = []\n",
        "\n",
        "for line in lines:\n",
        "    # Assuming the format is 'Degree Category: Percentage%'\n",
        "    parts = line.strip().split(': ')\n",
        "    if len(parts) == 2:\n",
        "        labels.append(parts[0])\n",
        "        percentage = float(parts[1].strip('%'))  # Remove '%' and convert to float\n",
        "        percentages.append(percentage)\n",
        "\n",
        "# Plotting the pie chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.pie(percentages, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Bachelor\\'s Degrees Conferred at University at Buffalo (2021-2022)')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()\n"
      ],
      "id": "ijeWGu8MuFfh"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}